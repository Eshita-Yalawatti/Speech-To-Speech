{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7v23wpSlrhj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495c8c36-91e2-4b48-f219-cc313c231126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchaudio"
      ],
      "metadata": {
        "id": "ZRUtykiw8J3C"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = \"/content/colorofsky.wav\"\n",
        "waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "print(waveform)\n",
        "print(sample_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBq0V2Di98wr",
        "outputId": "9dd00c6c-5049-4bfe-c753-8f44f46c6a25"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.0090, -0.0098, -0.0111],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0032, -0.0009,  0.0003]])\n",
            "48000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if sample_rate != 16000:\n",
        "  resample = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "  waveform = resample(waveform)\n",
        "\n",
        "if waveform.shape[0] > 1:\n",
        "  waveform = waveform.mean(dim=0, keepdim=True)"
      ],
      "metadata": {
        "id": "Qyq6TYyF-0uf"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2Model\n",
        "\n",
        "# Load the pre-trained model from Hugging Face\n",
        "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xwVpy_l7NPV",
        "outputId": "569c5397-0374-4bd1-d288-b6aa8f3b6e17"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:312: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hYVD6Ls37e5L",
        "outputId": "d7f03af1-e3d7-4e28-c02f-c75bad0acf48"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Wav2Vec2Model(\n",
              "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
              "    (conv_layers): ModuleList(\n",
              "      (0): Wav2Vec2GroupNormConvLayer(\n",
              "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
              "        (activation): GELUActivation()\n",
              "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
              "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "        (activation): GELUActivation()\n",
              "      )\n",
              "      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
              "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
              "        (activation): GELUActivation()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (feature_projection): Wav2Vec2FeatureProjection(\n",
              "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): Wav2Vec2Encoder(\n",
              "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
              "      (conv): ParametrizedConv1d(\n",
              "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
              "        (parametrizations): ModuleDict(\n",
              "          (weight): ParametrizationList(\n",
              "            (0): _WeightNorm()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (padding): Wav2Vec2SamePadLayer()\n",
              "      (activation): GELUActivation()\n",
              "    )\n",
              "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
              "        (attention): Wav2Vec2SdpaAttention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): Wav2Vec2FeedForward(\n",
              "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr4kp9tM7v__",
        "outputId": "55948064-aa72-497d-f4b9-f4b0c60e5894"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:312: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "projection = nn.Linear(encoder.config.hidden_size, 1024)"
      ],
      "metadata": {
        "id": "nkprnnJr79Un"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waveform.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZbhco2H-XcH",
        "outputId": "9537f4af-09b4-49d7-ac87-4c99e0ab1a4a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 49536])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "  waveform = encoder(waveform)\n",
        "\n",
        "print(waveform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I0kE0gc_dkv",
        "outputId": "5ac2a6f1-04fb-4e95-9b99-285f8fba24f6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wav2Vec2BaseModelOutput(last_hidden_state=tensor([[[-0.0781,  0.1688,  0.0316,  ...,  0.3240,  0.4987, -0.3718],\n",
            "         [-0.0874,  0.0913, -0.1814,  ...,  0.2342,  0.5450, -0.5056],\n",
            "         [-0.0818,  0.0838, -0.1880,  ...,  0.2107,  0.5439, -0.5101],\n",
            "         ...,\n",
            "         [ 0.1371,  0.2922, -0.0030,  ...,  0.2240,  0.2370, -0.3827],\n",
            "         [ 0.1242,  0.2938, -0.0057,  ...,  0.3437,  0.2205, -0.4508],\n",
            "         [ 0.1906,  0.3058, -0.1881,  ...,  0.2661,  0.1275, -0.3255]]]), extract_features=tensor([[[ 0.3463, -0.0382, -0.0162,  ..., -0.4728, -0.1189, -0.3435],\n",
            "         [ 0.3463, -0.0382, -0.0162,  ..., -0.4728, -0.1189, -0.3435],\n",
            "         [ 0.3463, -0.0382, -0.0162,  ..., -0.4728, -0.1189, -0.3435],\n",
            "         ...,\n",
            "         [ 0.5760, -0.3437,  0.6435,  ...,  0.0543, -0.2448,  0.3804],\n",
            "         [ 0.4357, -0.1091,  0.5273,  ...,  0.0175,  0.0106,  0.2667],\n",
            "         [ 0.7384, -0.2758,  0.4743,  ..., -0.2888, -0.2321,  0.1672]]]), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waveform = waveform.last_hidden_state\n",
        "\n",
        "print(waveform)\n",
        "print(waveform.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZmOtpHGlAGne",
        "outputId": "8227a729-5504-406b-bb15-2840b3578e73"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.0781,  0.1688,  0.0316,  ...,  0.3240,  0.4987, -0.3718],\n",
            "         [-0.0874,  0.0913, -0.1814,  ...,  0.2342,  0.5450, -0.5056],\n",
            "         [-0.0818,  0.0838, -0.1880,  ...,  0.2107,  0.5439, -0.5101],\n",
            "         ...,\n",
            "         [ 0.1371,  0.2922, -0.0030,  ...,  0.2240,  0.2370, -0.3827],\n",
            "         [ 0.1242,  0.2938, -0.0057,  ...,  0.3437,  0.2205, -0.4508],\n",
            "         [ 0.1906,  0.3058, -0.1881,  ...,  0.2661,  0.1275, -0.3255]]])\n",
            "torch.Size([1, 154, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waveform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuBRTGG2ARr6",
        "outputId": "3fde9f12-8d31-422e-8056-c3ae0451113f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0781,  0.1688,  0.0316,  ...,  0.3240,  0.4987, -0.3718],\n",
              "         [-0.0874,  0.0913, -0.1814,  ...,  0.2342,  0.5450, -0.5056],\n",
              "         [-0.0818,  0.0838, -0.1880,  ...,  0.2107,  0.5439, -0.5101],\n",
              "         ...,\n",
              "         [ 0.1371,  0.2922, -0.0030,  ...,  0.2240,  0.2370, -0.3827],\n",
              "         [ 0.1242,  0.2938, -0.0057,  ...,  0.3437,  0.2205, -0.4508],\n",
              "         [ 0.1906,  0.3058, -0.1881,  ...,  0.2661,  0.1275, -0.3255]]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "waveform = projection(waveform)"
      ],
      "metadata": {
        "id": "wbU0RDiLAg0a"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(waveform)\n",
        "print(waveform.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMCbqWi1Aqqh",
        "outputId": "eb915ce0-e640-4b85-dae7-59ee45b7e5c9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0921, -0.1642,  0.1744,  ...,  0.0982, -0.1150,  0.1578],\n",
            "         [ 0.1408, -0.0401,  0.1541,  ...,  0.1644, -0.1875,  0.1902],\n",
            "         [ 0.1378, -0.0298,  0.1452,  ...,  0.1770, -0.2041,  0.1955],\n",
            "         ...,\n",
            "         [ 0.0021, -0.1432,  0.2494,  ..., -0.0727, -0.1309, -0.5114],\n",
            "         [-0.0091, -0.0453,  0.2223,  ..., -0.0582, -0.0601, -0.4734],\n",
            "         [ 0.0040, -0.1545,  0.1704,  ..., -0.1562,  0.0898, -0.5249]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "torch.Size([1, 154, 1024])\n"
          ]
        }
      ]
    }
  ]
}